# Map Locations AI - Configuration

# LLM Settings
llm:
  model: "gpt-4o-mini"  # Can be changed to "gpt-4o" for production
  temperature: 0.1      # Low temperature for consistent extraction
  max_tokens: 2000      # Sufficient for location extraction responses
  timeout: 120          # Increased timeout in seconds for API calls

# Processing Settings
processing:
  chunk_size: 50        # Reduced chunk size for faster processing
  overlap_size: 10      # Number of overlapping lines between chunks

# Output Settings
output:
  temp_dir: "map_locations_ai/temp"      # Directory for temporary YAML files
  trace_dir: "map_locations_ai/trace"    # Directory for trace logs
  chunk_prefix: "chunk" # Prefix for chunk files (chunk_001.yaml, etc.)
